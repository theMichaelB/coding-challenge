date: 4-nov-2025
title: AI Coding for Everyone: Safe and Accessible by Design

---
Anyone who’s spent five minutes reading about AI coding has seen the disaster stories: agents deleting production databases, resetting GitHub repos to zero, or spiraling into infinite loops of self-destruction.

Here’s the thing: treating AI like a junior developer is exactly right. Not because AI is dumb, but because the management principle is the same. You don’t hand a new hire root access, drop a 28-page manual on their desk, and hope the “don’t delete production” line sticks.

Developers solved this problem decades ago. It’s called least privilege – you get the access you need, and nothing more. People still screw up, but they rarely take the company down with them.

AI platforms, though? Many act like security is a luxury add-on. Some even sell it that way – basic access controls tucked behind an enterprise paywall. Which is absurd.
There’s a better foundation hiding in plain sight. The hyperscale clouds – AWS, Azure, and Google Cloud – already run most of the world’s secure infrastructure. They’ve been tested, hardened, and endlessly documented. They’re complicated, yes, and setting up permissions can still make my head hurt, even after working with them since launch. They’re also dangerous if you don’t know what you’re doing – there’s an AWS instance that can quietly cost over $91,000 a month.

For even the most complex enterprise environments, good access control and governance make these platforms incredibly safe places to operate – even for people who aren’t experts. And that’s their real strength.

That same foundation also makes them the perfect environment for AI systems. The security models, compliance standards, and access frameworks are already proven. And the best part? AI actually understands them. The documentation is so rich and consistent that AI can reliably configure them, line by line.

With the right planning, you can use those access-control systems to define, in exact detail, what AI is allowed to do. That’s the key to safe autonomy – constraint by design, not by fear. And just as you can define what AI can do, you can define what you can do, using those same systems to keep yourself out of trouble.

So I’m going to prove it. Over the next few posts, I’ll build an AI developer platform on AWS that’s secure enough to make dangerously-skip-permissions the default command – not as a reckless option, but as proof that safety can be built into the foundations rather than bolted on later.

Once that’s done, I want to explore what happens when you treat AI as a genuine build partner – on a platform that already contains the building blocks for almost anything you can imagine. These tools shouldn’t belong only to seasoned ops engineers and developers. AI makes them accessible to everyone, and I want to show how to use them safely.

The final challenge is accessibility. I want every part of this series to be approachable, whether you’re a hairdresser or a sheep shearer. I want to create something that gives people the confidence to try to build something with AI.

Right now, I have no idea how I’m going to explain the AWS permissions model to someone who barely knows what AWS is. But it’s a challenge worth taking on.

So stick around, it is going to be a wild and bumpy ride.
